{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5b17345d-fd7a-427d-9bd7-6478dadd4fd1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### TRƯỜNG ĐẠI HỌC CÔNG NGHIỆP\n",
    "### THÀNH PHỐ HỒ CHÍ MINH\n",
    " \n",
    "### KHOA Công nghệ Thông tin   \n",
    "## ĐỀ THI GIỮA KỲ\n",
    "### Môn thi : Nhập môn dữ liệu lớn \n",
    "### Lớp/Lớp học phần:  DHKHDL16A\n",
    "* Ngày thi: 24/10/2023\n",
    "* Thời gian làm bài: 60 phút (Không kể thời gian phát đề)\n",
    "* Thí sinh được sử dụng tài liệu và tra cứu Internet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6ed0438a-5635-4a58-8ea9-d2a08bcaadb0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Lưu ý:\n",
    "\n",
    "* Để chuẩn bị cho thi giữa kỳ hôm nay, các bạn phải tạo một tài khoản community của Databricks. Các bạn làm theo hướng dẫn trong\n",
    "https://lms.iuh.edu.vn/mod/assign/view.php?id=240288\n",
    "(Lab 4 - Databricks and PySpark.pdf)\n",
    "\n",
    "* Đầu buổi thi, giám thị sẽ chỉ dẫn tạo tài khoản Databricks cho các bạn chưa tạo được tài khoản\n",
    "* Các bạn sẽ upload file Introduction_to_Big_Data_midterm.ipynb lên Databricks\n",
    "* Đổi tên file ipynb thành <mã sinh viên>_<Họ Tên>_midterm.ipynb (Ví dụ 123456_NguyenVanA_midterm.ipynb)\n",
    "* Sau khi hoàn thành bài thi trên Databricks, download notebook và nộp file ipynb trong LMS tại địa chỉ do giám thị cung cấp\n",
    "* Các phần code để test chỉ để giúp các bạn viết code, nếu các bài test bị sai, code của bạn vẫn được chấm điểm\n",
    "* Link nộp bài (chỉ nộp file ipynb) https://lms.iuh.edu.vn/mod/assign/view.php?id=246250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a6cff1e1-360f-4431-ad75-50b17605e4ea",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Họ và tên: Hồ Hoàng Vân Anh\n",
    "### Mã sinh viên: 20098521\n",
    "### Số máy: H4.02.03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3fb43479-ae77-4d48-a2b4-eaf005c8da14",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Câu 1 (0.5 điểm) Tạo RDD từ một list đầu vào\n",
    "Viết một hàm trong Pyspark để tạo một RDD từ một list đầu vào sử dụng method `sc.parallelize`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c22f86e8-bde1-46b1-898d-daeb66358760",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def createRDD(inList):\n",
    "  # Your code goes here\n",
    "  outRDD = sc.parallelize(inList)\n",
    "    \n",
    "  return outRDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b380411-2886-482c-b952-edb99aea65f3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Test \n",
    "wordsList = ['cat', 'elephant', 'rat', 'rat', 'cat']\n",
    "\n",
    "assert createRDD(wordsList).collect() == ['cat', 'elephant', 'rat', 'rat', 'cat'], \"create_rdd() error!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2f22ea5f-571d-4696-aa4b-94ad4a601f83",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Câu 2 (0.5 điểm) Chuyển đổi một từ tiếng Anh sang dạng số nhiều\n",
    "\n",
    "Viết một hàm trong Pyspark để nhận một danh từ tiếng Anh và trả về dạng số nhiều của từ. Để đơn giản, ở đây chúng ta sẽ thêm 's' vào cuối danh từ đầu vào. Ví dụ 'cat' => 'cats'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f01abe81-01dd-4e54-bb9f-85d453731a10",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def makePlural(word):\n",
    "\n",
    "    \"\"\"Adds an 's' to `word`.\n",
    "\n",
    "    Note:\n",
    "        This is a simple function that only adds an 's'.  No attempt is made to follow proper\n",
    "        pluralization rules.\n",
    "\n",
    "    Args:\n",
    "        word (str): A string.\n",
    "\n",
    "    Returns:\n",
    "        str: A string with 's' added to it.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Your code goes here\n",
    "    return word + 's'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "125abe6c-edb0-4bdc-85b2-6260d740a336",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "assert makePlural('rat') == 'rats', \"makePlural() failed\"\n",
    "assert makePlural('cat') == 'cats', \"makePlural() failed\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5cf35536-8b55-4cfb-8c27-f750cd551c4f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Câu 3 (0.5 điểm) Dùng hàm map() để chuyển một list danh từ sang số nhiều\n",
    "\n",
    "Sử dụng hàm map() và hàm makePlural() trong câu 2 để chuyển một list danh từ sang số nhiều"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d53d994-1026-4268-bb2b-d761bf1945b1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def makeListPlural(inputRDD):\n",
    "  \n",
    "  # Your codes goes here\n",
    "  outputRDD = inputRDD.map(makePlural)\n",
    "  return outputRDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5857a83f-7f49-4105-a8c5-ac50a212ee79",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "rdd_test = sc.parallelize(['house', 'school', 'dog'])\n",
    "assert makeListPlural(rdd_test).collect() == ['houses', 'schools', 'dogs'], \"makeListPlural() error!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b9279024-9c04-4080-81f5-a09abbd096fc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Câu 4 (0.5 điểm) Pair RDDs\n",
    "\n",
    "Một pair RDD là một RDD trong đó mỗi phần tử là một tuple `(k, v)` trong đó `k` là key và `v` là value. Trong Câu hỏi này, bạn sẽ tạo một pair dạng `('<word>', 1)` cho mỗi phần từ của RDD đầu vào. Sử dụng hàm map() và hàm `lambda()` để tạo ra RDD mới."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fad66543-90c3-4487-9b8a-2d594284379d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def createPairRDD(inputRDD):\n",
    "  \n",
    "  # Your code goes here\n",
    "  outputRDD = inputRDD.map(lambda word: (word, 1))\n",
    "  \n",
    "  return outputRDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd52d9bf-bb11-4798-9ad7-6310ade9b114",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "input_rdd = sc.parallelize(['cat', 'elephant', 'rat', 'rat', 'cat'])\n",
    "wordPairs = createPairRDD(input_rdd)\n",
    "\n",
    "assert wordPairs.collect() ==\\\n",
    "                  [('cat', 1), ('elephant', 1), ('rat', 1),\\\n",
    "                   ('rat', 1), ('cat', 1)],\\\n",
    "                  'createPairRDD() failed'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "80be274b-967a-49d8-8da1-39a1b4438f58",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Câu 5 (0.5 điểm) Sử dụng pair RDD để đếm từ\n",
    "Trong câu này chúng ta sẽ sử dụng các hàm xây dựng trên đây để đếm số lần xuất hiện của mỗi từ trong một RDD. Hàm nhận một RDD đầu vào và trả về một pair RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6cbcda5b-d9f2-45c1-9510-ac4bd7f5bebf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def wordCount(inputRDD):\n",
    "  \n",
    "  # Your code goes here\n",
    "    word_counts = inputRDD.map(lambda word: (word, 1)).reduceByKey(lambda a, b: a + b)\n",
    "    \n",
    "    return word_counts\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8aadc190-9e20-4fe2-93e4-eba34b393675",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "inputRDD = sc.parallelize(['cat', 'elephant', 'rat', 'rat', 'cat'])\n",
    "wordCount(inputRDD).collect()\n",
    "assert sorted(wordCount(inputRDD).collect()) == [('cat', 2), ('elephant', 1), ('rat', 2)],\\\n",
    "                  'incorrect value for wordCounts'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "275d48cd-5d62-434e-b8d6-c0ddab3e60e5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Câu 6 (0.5 điểm): Tìm các từ duy nhất trong một RDD \n",
    "Cho một RDD gồm nhiều từ đầu vào, viết một hàm để trả về một RDD chỉ gồm các từ duy nhất (mỗi từ chỉ xuất hiện một lần)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de34b207-39c2-4eff-9968-90ea6d259842",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def getUniqueWords(inputRDD):\n",
    "    # Sử dụng phương thức distinct để lấy các từ duy nhất\n",
    "    outputRDD = inputRDD.distinct()\n",
    "    \n",
    "    return outputRDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6fd6a0b-3e0b-4f59-af86-0323e8b46eee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "inputRDD = sc.parallelize(['cat', 'elephant', 'rat', 'rat', 'cat'])\n",
    "assert sorted(getUniqueWords(inputRDD).collect()) == ['cat', 'elephant', 'rat'], 'getUniqueWords() failed' \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "731d9505-a384-4fbd-9a2c-312092864039",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##  Câu 7 (0.5 điểm) Viết hoa và chấm câu\n",
    "\n",
    "Khi làm việc với dữ liệu thực tế, chúng ta cần xem xét:\n",
    "   + Một từ có thể được viết hoa hoặc viết thường nhưng vẫn coi là cùng một từ (ví dụ: Spark và spark nên được tính là cùng một từ).\n",
    "   + Cần loại bỏ tất cả các dấu câu.\n",
    "   + Bất kỳ khoảng trắng đầu hoặc cuối trên một dòng phải được loại bỏ.\n",
    "\n",
    "Xây dựng hàm removePunctuation() để chuyển đổi tất cả văn bản thành chữ thường, loại bỏ bất kỳ dấu câu nào và xóa các khoảng trắng ở đầu và cuối."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c3bfe6d-ad5a-4dd3-bc79-71650039579b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def removePunctuation(text):\n",
    "    \"\"\"Removes punctuation, changes to lower case, and strips leading and trailing spaces.\n",
    "\n",
    "    Note:\n",
    "        Only spaces, letters, and numbers should be retained.  Other characters should should be\n",
    "        eliminated (e.g. it's becomes its).  Leading and trailing spaces should be removed after\n",
    "        punctuation is removed.\n",
    "\n",
    "    Args:\n",
    "        text (str): A string.\n",
    "\n",
    "    Returns:\n",
    "        str: The cleaned up string.\n",
    "    \"\"\"\n",
    "    # Your code goes here\n",
    "    # Loại bỏ dấu câu và chuyển thành chữ thường\n",
    "    output_text = re.sub(r'[^\\w\\s]', '', text).lower()\n",
    "    \n",
    "    # Loại bỏ khoảng trắng ở đầu và cuối\n",
    "    output_text = output_text.strip()\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da1fbb49-5c65-4f9c-84cc-3c194fa580b0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TEST Capitalization and punctuation (4b)\n",
    "assert  removePunctuation(\" The Elephant's 4 cats. \") == 'the elephants 4 cats',\\\n",
    "                  'removePunctuation() failed'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7ed0734d-00be-4578-b449-e0463274def7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##  Câu 8 (1 điểm) Đếm từ trong một text file\n",
    "Trong câu này, chúng ta sẽ xây dựng một hàm wordCountForFiles() để đếm từ trong một file text. Chúng ta sẽ sử dụng [Complete Works of William Shakespeare](http://www.gutenberg.org/ebooks/100) từ [Project Gutenberg](http://www.gutenberg.org/wiki/Main_Page). Nếu lấy các từ xuất hiện nhiều nhất, kết quả của các bạn sẽ có dạng dưới đây:\n",
    "\n",
    "* the: 27361\n",
    "* and: 26028\n",
    "* i: 20681\n",
    "* to: 19150\n",
    "* of: 17463\n",
    "* a: 14593\n",
    "* you: 13615\n",
    "* my: 12481\n",
    "* in: 10956\n",
    "* that: 10890\n",
    "* is: 9134\n",
    "* not: 8497\n",
    "* with: 7771\n",
    "* me: 7769\n",
    "* it: 7678"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5f6e3f1e-accd-4cda-bc72-08382feddd07",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Load các vở kịch của Shakespeare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b68c69e-2fad-4961-a351-c0dae4a29b99",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1609', '', 'THE SONNETS', '', 'by William Shakespeare', '', '', '', '                     1', '  From fairest creatures we desire increase', '  That thereby beautys rose might never die', '  But as the riper should by time decease', '  His tender heir might bear his memory', '  But thou contracted to thine own bright eyes', '  Feedst thy lights flame with selfsubstantial fuel']\n0: 1609\n1: \n2: THE SONNETS\n3: \n4: by William Shakespeare\n5: \n6: \n7: \n8:                      1\n9:   From fairest creatures we desire increase\n10:   That thereby beautys rose might never die\n11:   But as the riper should by time decease\n12:   His tender heir might bear his memory\n13:   But thou contracted to thine own bright eyes\n14:   Feedst thy lights flame with selfsubstantial fuel\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "fileName = \"dbfs:/\" + os.path.join('databricks-datasets', 'cs100', 'lab1', 'data-001', 'shakespeare.txt')\n",
    "\n",
    "shakespeareRDD = sc.textFile(fileName, 8).map(removePunctuation)\n",
    "print(shakespeareRDD.take(15))\n",
    "print('\\n'.join(shakespeareRDD\\\n",
    "                .zipWithIndex().map(lambda x: '{0}: {1}'.format(x[1], x[0]))\\\n",
    "                .take(15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c67bb86a-b483-489c-ad1a-a182b7e1f0d7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the: 27361\nand: 26028\ni: 20681\nto: 19150\nof: 17463\na: 14593\nyou: 13615\nmy: 12481\nin: 10956\nthat: 10890\nis: 9134\nnot: 8497\nwith: 7771\nme: 7769\nit: 7678\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "\n",
    "# Định nghĩa hàm removePunctuation\n",
    "import re\n",
    "\n",
    "def removePunctuation(text):\n",
    "    return re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "# Hàm tách các từ từ một dòng\n",
    "def splitWords(line):\n",
    "    words = line.split()\n",
    "    cleaned_words = [removePunctuation(word).lower() for word in words]\n",
    "    return cleaned_words\n",
    "\n",
    "# Đường dẫn đến tệp văn bản Shakespeare\n",
    "fileName = \"dbfs:/\" + os.path.join('databricks-datasets', 'cs100', 'lab1', 'data-001', 'shakespeare.txt')\n",
    "\n",
    "# Đọc tệp văn bản và tách các từ\n",
    "shakespeareRDD = sc.textFile(fileName, 8).flatMap(splitWords)\n",
    "\n",
    "# Đếm số lần xuất hiện của mỗi từ\n",
    "wordCounts = shakespeareRDD.map(lambda word: (word, 1)).reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "# Sắp xếp kết quả theo số lần xuất hiện\n",
    "sortedWordCounts = wordCounts.map(lambda x: (x[1], x[0])).sortByKey(ascending=False)\n",
    "\n",
    "# Hiển thị các từ xuất hiện nhiều nhất\n",
    "topWords = sortedWordCounts.take(15)\n",
    "for count, word in topWords:\n",
    "    print(f\"{word}: {count}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5faeab1d-a202-4bb6-92da-e73d42518f4c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##  Câu 9 (0.5 điểm)\n",
    "\n",
    "Đoạn mã sau liệt kê tất cả các bộ dữ liệu Databricks có sẵn trong thư mục flights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0d099a5-1ad7-4dfa-b684-5b166415a5c6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/databricks-datasets/learning-spark-v2/flights/README.md</td><td>README.md</td><td>412</td><td>1577997753000</td></tr><tr><td>dbfs:/databricks-datasets/learning-spark-v2/flights/airport-codes-na.txt</td><td>airport-codes-na.txt</td><td>11411</td><td>1577997753000</td></tr><tr><td>dbfs:/databricks-datasets/learning-spark-v2/flights/departuredelays.csv</td><td>departuredelays.csv</td><td>33396236</td><td>1577997754000</td></tr><tr><td>dbfs:/databricks-datasets/learning-spark-v2/flights/summary-data/</td><td>summary-data/</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/databricks-datasets/learning-spark-v2/flights/README.md",
         "README.md",
         412,
         1577997753000
        ],
        [
         "dbfs:/databricks-datasets/learning-spark-v2/flights/airport-codes-na.txt",
         "airport-codes-na.txt",
         11411,
         1577997753000
        ],
        [
         "dbfs:/databricks-datasets/learning-spark-v2/flights/departuredelays.csv",
         "departuredelays.csv",
         33396236,
         1577997754000
        ],
        [
         "dbfs:/databricks-datasets/learning-spark-v2/flights/summary-data/",
         "summary-data/",
         0,
         0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dbutils.fs.ls('/databricks-datasets/learning-spark-v2/flights'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "33fbbe3c-7ea3-4e4d-aee3-09580c59ad48",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\"departuredelays.csv\" có 5 cột:\n",
    "* Cột date chứa một số như 02190925. Khi được chuyển đổi, số này sẽ ánh xạ tới 02-19 09:25 AM.\n",
    "* Cột delay cho biết độ trễ tính bằng phút giữa thời gian khởi hành theo lịch trình và thời gian khởi hành thực tế. Khởi hành sớm hiển thị số âm.\n",
    "* Cột distance cho biết khoảng cách tính bằng dặm từ sân bay xuất phát đến sân bay đích.\n",
    "* Cột origin chứa mã sân bay IATA điểm xuất phát.\n",
    "* Cột destination chứa mã sân bay IATA điểm đến.\n",
    "\n",
    "Sử dụng đường dẫn \"/databricks-datasets/learning-spark-v2/flights/departuredelays.csv\" để đọc dữ liệu từ file departuredelays.csv vào DataFrame delay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98f9cc57-8ffa-4d6a-afaa-4978114011c4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- date: string (nullable = true)\n |-- delay: string (nullable = true)\n |-- distance: string (nullable = true)\n |-- origin: string (nullable = true)\n |-- destination: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SQLContext \n",
    "from pyspark.sql import SparkSession\n",
    "# Your code goes here\n",
    "# Tạo một phiên Spark\n",
    "spark = SparkSession.builder.appName(\"example\").getOrCreate()\n",
    "\n",
    "# Đường dẫn đến tệp departuredelays.csv\n",
    "file_path = \"/databricks-datasets/learning-spark-v2/flights/departuredelays.csv\"\n",
    "\n",
    "# Đọc dữ liệu từ tệp vào DataFrame\n",
    "delay = spark.read.csv(file_path, header=True)\n",
    "\n",
    "delay.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0198d80a-4f16-4d39-aeaf-160e25cc529a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##  Thực hiện các câu sau bằng SQL Query và DataFrame Operations\n",
    "##  Câu 10 (0.5 điểm) Hiển thị 10 dòng dữ liệu\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88c61a51-7281-4ce0-9f46-44de5dcb3dfc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+--------+------+-----------+\n|    date|delay|distance|origin|destination|\n+--------+-----+--------+------+-----------+\n|01011245|    6|     602|   ABE|        ATL|\n|01020600|   -8|     369|   ABE|        DTW|\n|01021245|   -2|     602|   ABE|        ATL|\n|01020605|   -4|     602|   ABE|        ATL|\n|01031245|   -4|     602|   ABE|        ATL|\n|01030605|    0|     602|   ABE|        ATL|\n|01041243|   10|     602|   ABE|        ATL|\n|01040605|   28|     602|   ABE|        ATL|\n|01051245|   88|     602|   ABE|        ATL|\n|01050605|    9|     602|   ABE|        ATL|\n+--------+-----+--------+------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "# SQL Query\n",
    "# Your code goes here\n",
    "# Đăng ký DataFrame thành một tạm thời view để sử dụng SQL Query\n",
    "delay.createOrReplaceTempView(\"flight_data\")\n",
    "spark.sql(\"SELECT * FROM flight_data LIMIT 10\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20d2087e-17a9-48a2-b095-a7421e18ad81",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+--------+------+-----------+\n|    date|delay|distance|origin|destination|\n+--------+-----+--------+------+-----------+\n|01011245|    6|     602|   ABE|        ATL|\n|01020600|   -8|     369|   ABE|        DTW|\n|01021245|   -2|     602|   ABE|        ATL|\n|01020605|   -4|     602|   ABE|        ATL|\n|01031245|   -4|     602|   ABE|        ATL|\n|01030605|    0|     602|   ABE|        ATL|\n|01041243|   10|     602|   ABE|        ATL|\n|01040605|   28|     602|   ABE|        ATL|\n|01051245|   88|     602|   ABE|        ATL|\n|01050605|    9|     602|   ABE|        ATL|\n+--------+-----+--------+------+-----------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "# DataFrame Operations\n",
    "# Your code goes here\n",
    "delay.show(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "78a8e1c9-c324-483b-9845-f1a7a4841b3b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##  Câu 11 (0.5 điểm) Tìm các chuyến bay lúc 10-6 12:15PM (date = \"1061215\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d10f2a89-6ac6-4746-89fc-b7cca6ad2738",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+--------+------+-----------+\n|date|delay|distance|origin|destination|\n+----+-----+--------+------+-----------+\n+----+-----+--------+------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "# SQL Query\n",
    "# Your code goes here\n",
    "result = spark.sql(\"SELECT * FROM flight_data WHERE date = '1061215'\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e74cd92-bcf7-41a1-a821-209aceaf4082",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+--------+------+-----------+\n|date|delay|distance|origin|destination|\n+----+-----+--------+------+-----------+\n+----+-----+--------+------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "# DataFrame Operations\n",
    "# Your code goes here\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Sử dụng DataFrame Operations để tìm các chuyến bay vào lúc 10-6 12:15PM\n",
    "result = delay.filter(col(\"date\") == \"1061215\")\n",
    "result.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8eae8b8c-2df5-4cb3-b291-7a8c3f1ca876",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Câu 12 Tìm các chuyến bay có khoảng cách lớn 1000 dặm và hiển thị theo thứ tự giảm dần\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4135baef-1aea-4012-9808-053599f3d6da",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+--------+------+-----------+\n|    date|delay|distance|origin|destination|\n+--------+-----+--------+------+-----------+\n|01011625|   -4|    4330|   HNL|        JFK|\n|01010900|    6|    4330|   JFK|        HNL|\n|03011625|   -1|    4330|   HNL|        JFK|\n|01210900|   -3|    4330|   JFK|        HNL|\n|02011625|   -1|    4330|   HNL|        JFK|\n|01020900|    1|    4330|   JFK|        HNL|\n|03291530|   37|    4330|   HNL|        JFK|\n|01030900|  784|    4330|   JFK|        HNL|\n|01211625|  115|    4330|   HNL|        JFK|\n|01040900|  111|    4330|   JFK|        HNL|\n|03021625|   14|    4330|   HNL|        JFK|\n|01050900|   98|    4330|   JFK|        HNL|\n|02271625|   -7|    4330|   HNL|        JFK|\n|01060900|   -2|    4330|   JFK|        HNL|\n|03051625|   -6|    4330|   HNL|        JFK|\n|01070900|    3|    4330|   JFK|        HNL|\n|01021625|  110|    4330|   HNL|        JFK|\n|01080900|   14|    4330|   JFK|        HNL|\n|03061625|   -2|    4330|   HNL|        JFK|\n|01090900|   -3|    4330|   JFK|        HNL|\n+--------+-----+--------+------+-----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# SQL Query\n",
    "# Your code goes here\n",
    "result = spark.sql(\"SELECT * FROM flight_data WHERE distance > 1000 ORDER BY distance DESC\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c284ddb-b4ab-4c50-8e02-03356879233c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+--------+------+-----------+\n|    date|delay|distance|origin|destination|\n+--------+-----+--------+------+-----------+\n|01011625|   -4|    4330|   HNL|        JFK|\n|01010900|    6|    4330|   JFK|        HNL|\n|03011625|   -1|    4330|   HNL|        JFK|\n|01210900|   -3|    4330|   JFK|        HNL|\n|02011625|   -1|    4330|   HNL|        JFK|\n|01020900|    1|    4330|   JFK|        HNL|\n|03291530|   37|    4330|   HNL|        JFK|\n|01030900|  784|    4330|   JFK|        HNL|\n|01211625|  115|    4330|   HNL|        JFK|\n|01040900|  111|    4330|   JFK|        HNL|\n|03021625|   14|    4330|   HNL|        JFK|\n|01050900|   98|    4330|   JFK|        HNL|\n|02271625|   -7|    4330|   HNL|        JFK|\n|01060900|   -2|    4330|   JFK|        HNL|\n|03051625|   -6|    4330|   HNL|        JFK|\n|01070900|    3|    4330|   JFK|        HNL|\n|01021625|  110|    4330|   HNL|        JFK|\n|01080900|   14|    4330|   JFK|        HNL|\n|03061625|   -2|    4330|   HNL|        JFK|\n|01090900|   -3|    4330|   JFK|        HNL|\n+--------+-----+--------+------+-----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# DataFrame Operations\n",
    "# Your code goes here\n",
    "# Tìm các chuyến bay có khoảng cách lớn hơn 1000 dặm\n",
    "filtered_flights = delay.filter(col(\"distance\") > 1000)\n",
    "\n",
    "# Sắp xếp kết quả theo khoảng cách giảm dần\n",
    "sorted_flights = filtered_flights.orderBy(col(\"distance\").desc())\n",
    "\n",
    "# Hiển thị kết quả\n",
    "sorted_flights.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ec35fcab-0f28-49f9-b9f7-4713e311a498",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Câu 13 Tìm các chuyến bay từ San Francisco (SFO) đến Chicago (ORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c6f131c-c572-43da-97df-6e05d07ef33f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+--------+------+-----------+\n|    date|delay|distance|origin|destination|\n+--------+-----+--------+------+-----------+\n|01011800|    0|    1604|   SFO|        ORD|\n|01010925|   -3|    1604|   SFO|        ORD|\n|01010555|   -6|    1604|   SFO|        ORD|\n|01012330|   32|    1604|   SFO|        ORD|\n|01011110|   -5|    1604|   SFO|        ORD|\n|01011410|  124|    1604|   SFO|        ORD|\n|01021800|  113|    1604|   SFO|        ORD|\n|01020925|    9|    1604|   SFO|        ORD|\n|01020555|   -4|    1604|   SFO|        ORD|\n|01022330|  326|    1604|   SFO|        ORD|\n|01021110|   34|    1604|   SFO|        ORD|\n|01021410|  190|    1604|   SFO|        ORD|\n|01031800|   -5|    1604|   SFO|        ORD|\n|01030925|   -5|    1604|   SFO|        ORD|\n|01030555|   -5|    1604|   SFO|        ORD|\n|01032330|   -3|    1604|   SFO|        ORD|\n|01031110|   -6|    1604|   SFO|        ORD|\n|01031410|   36|    1604|   SFO|        ORD|\n|01040925|   -2|    1604|   SFO|        ORD|\n|01040555|   -4|    1604|   SFO|        ORD|\n+--------+-----+--------+------+-----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# SQL Query\n",
    "# Your code goes here\n",
    "result = spark.sql(\"SELECT * FROM flight_data WHERE origin = 'SFO' AND destination = 'ORD'\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f812c41-bc67-4dc8-85ad-ea11ec13d4e1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+--------+------+-----------+\n|    date|delay|distance|origin|destination|\n+--------+-----+--------+------+-----------+\n|01011800|    0|    1604|   SFO|        ORD|\n|01010925|   -3|    1604|   SFO|        ORD|\n|01010555|   -6|    1604|   SFO|        ORD|\n|01012330|   32|    1604|   SFO|        ORD|\n|01011110|   -5|    1604|   SFO|        ORD|\n|01011410|  124|    1604|   SFO|        ORD|\n|01021800|  113|    1604|   SFO|        ORD|\n|01020925|    9|    1604|   SFO|        ORD|\n|01020555|   -4|    1604|   SFO|        ORD|\n|01022330|  326|    1604|   SFO|        ORD|\n|01021110|   34|    1604|   SFO|        ORD|\n|01021410|  190|    1604|   SFO|        ORD|\n|01031800|   -5|    1604|   SFO|        ORD|\n|01030925|   -5|    1604|   SFO|        ORD|\n|01030555|   -5|    1604|   SFO|        ORD|\n|01032330|   -3|    1604|   SFO|        ORD|\n|01031110|   -6|    1604|   SFO|        ORD|\n|01031410|   36|    1604|   SFO|        ORD|\n|01040925|   -2|    1604|   SFO|        ORD|\n|01040555|   -4|    1604|   SFO|        ORD|\n+--------+-----+--------+------+-----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# DataFrame Operations\n",
    "# Your code goes here\n",
    "result = delay.filter((col(\"origin\") == \"SFO\") & (col(\"destination\") == \"ORD\"))\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dde05e98-db9f-4715-8f6a-e1e6ba31897f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Câu 14 Tính trung bình độ trễ (phút) của các chuyến bay từ San Francisco (SFO) đến Chicago (ORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5fa670af-b87c-4008-95f8-54a2e14d526a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n|     average_delay|\n+------------------+\n|15.339675433687745|\n+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# SQL Query\n",
    "# Your code goes here\n",
    "result = spark.sql(\"\"\"\n",
    "    SELECT AVG(delay) AS average_delay\n",
    "    FROM flight_data\n",
    "    WHERE origin = 'SFO' AND destination = 'ORD'\n",
    "\"\"\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d85aa28b-2511-4c3d-b48d-d9676a10eea4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n|        avg(delay)|\n+------------------+\n|15.339675433687745|\n+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# DataFrame Operations\n",
    "# Your code goes here\n",
    "from pyspark.sql.functions import  avg\n",
    "# Lọc các chuyến bay từ SFO đến ORD\n",
    "filtered_flights = delay.filter((col(\"origin\") == \"SFO\") & (col(\"destination\") == \"ORD\"))\n",
    "\n",
    "# Tính trung bình độ trễ\n",
    "average_delay = filtered_flights.agg(avg(col(\"delay\")))\n",
    "\n",
    "# Hiển thị kết quả\n",
    "average_delay.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d07e8a3d-974d-4454-9865-94b296e31c6d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Câu 15 Tính độ trễ lớn nhất (phút) của các chuyến bay từ San Francisco (SFO) đến Chicago (ORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2c2761a-d9c7-4c26-a5a3-d155e362588b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n|max_delay|\n+---------+\n|       98|\n+---------+\n\n"
     ]
    }
   ],
   "source": [
    "# SQL Query\n",
    "# Your code goes here\n",
    "result_sql = spark.sql(\"\"\"\n",
    "    SELECT MAX(delay) AS max_delay\n",
    "    FROM flight_data\n",
    "    WHERE origin = 'SFO' AND destination = 'ORD'\n",
    "\"\"\")\n",
    "result_sql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c213b7b1-327c-4bbc-8ffc-72f01288adb5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n|max_delay|\n+---------+\n|       98|\n+---------+\n\n"
     ]
    }
   ],
   "source": [
    "# DataFrame Operations\n",
    "# Your code goes here\n",
    "from pyspark.sql.functions import  max\n",
    "\n",
    "# Sử dụng DataFrame Operations để tính độ trễ lớn nhất\n",
    "result_df = delay.filter((col(\"origin\") == \"SFO\") & (col(\"destination\") == \"ORD\")).agg(max(col(\"delay\")).alias(\"max_delay\"))\n",
    "result_df.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "20098521_HoHoangVanAnh_midterm",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
